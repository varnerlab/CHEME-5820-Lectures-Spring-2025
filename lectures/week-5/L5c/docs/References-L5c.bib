%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Jeffrey Varner at 2025-02-17 13:34:11 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@article{Lamani:2025aa,
	abstract = {Understanding human behavior and human action recognition are both essential components of effective surveillance video analysis for the purpose of guaranteeing public safety. However, existing approaches such as three-dimensional convolutional neural networks (3D CNN) and two-stream neural networks (2SNN) have computational hurdles due to the significant parameterization they require. In this paper, we offer HARNet, a specialized lightweight residual 3D CNN that is built on directed acyclic graphs and was created expressly to handle these issues and achieve effective human action detection. The suggested method presents an innovative pipeline for creating spatial motion data from raw video inputs, which makes successful latent representation learning of human motions easier to accomplish. This generated input is then supplied into HARNet, which processes spatial and motion information in a single stream in an effective manner, maximizing the benefits of both types of cues. The use of traditional machine learning classifiers is done in order to further improve the discriminative capacity of the features that have been learned. To be more specific, we use the latent representations that are stored in HARNet's fully connected layer and use them as our deep learnt features. After that, these features are entered into the Support Vector Machine (SVM) classifier in order to accomplish action recognition. In order to evaluate the HARNet-SVM method that was developed, empirical tests were run on commonly used action recognition datasets such as UCF101, HMDB51, and the KTH dataset. These tests were carried out in order to gather data for the evaluation. The experimental results show that our method is superior to other state-of-the-art approaches, achieving considerable performance increases of 2.75{\%} on UCF101, 10.94{\%} on HMDB51, and 0.18{\%} on the KTH dataset. These results were obtained by running the method on each dataset separately. Our findings demonstrate the usefulness of HARNet's lightweight design and highlight the significance of utilizing SVM classifiers with deep learnt features for the purpose of accurate and computationally efficient human activity recognition in surveillance videos. This work helps to the advancement of surveillance technology, which in turn makes video analysis in applications that take place in the real world safer and more dependable.},
	author = {Lamani, Dharmanna and Kumar, Pramod and Bhagyalakshmi, A. and Shanthi, J. Maria and Maguluri, Lakshmana Phaneendra and Arif, Mohammad and Dhanamjayulu, C. and K, Sathish Kumar. and Khan, Baseem},
	date = {2025/01/03},
	date-added = {2025-02-17 13:34:06 -0500},
	date-modified = {2025-02-17 13:34:06 -0500},
	doi = {10.1038/s41598-024-83529-7},
	id = {Lamani2025},
	isbn = {2045-2322},
	journal = {Scientific Reports},
	number = {1},
	pages = {672},
	title = {SVM directed machine learning classifier for human action recognition network},
	url = {https://doi.org/10.1038/s41598-024-83529-7},
	volume = {15},
	year = {2025},
	bdsk-url-1 = {https://doi.org/10.1038/s41598-024-83529-7}}

@article{Byvatov:2003aa,
	abstract = {The support vector machine (SVM) approach represents a data-driven method for solving classification tasks. It has been shown to produce lower prediction error compared to classifiers based on other methods like artificial neural networks, especially when large numbers of features are considered for sample description. In this review, the theory and main principles of the SVM approach are outlined, and successful applications in traditional areas of bioinformatics research are described. Current developments in techniques related to the SVM approach are reviewed which might become relevant for future functional genomics and chemogenomics projects. In a comparative study, we developed neural network and SVM models to identify small organic molecules that potentially modulate the function of G-protein coupled receptors. The SVM system was able to correctly classify approximately 90% of the compounds in a cross-validation study yielding a Matthews correlation coefficient of 0.78. This classifier can be used for fast filtering of compound libraries in virtual screening applications.},
	address = {Johann Wolfgang Goethe-Universit{\"a}t, Institut f{\"u}r Organische Chemie und Chemische Biologie, Frankfurt, Germany.},
	author = {Byvatov, Evgeny and Schneider, Gisbert},
	crdt = {2004/05/08 05:00},
	date = {2003},
	date-added = {2025-02-17 13:32:10 -0500},
	date-modified = {2025-02-17 13:32:10 -0500},
	dcom = {20040610},
	edat = {2004/05/08 05:00},
	issn = {1175-5636 (Print); 1175-5636 (Linking)},
	jid = {101150311},
	journal = {Appl Bioinformatics},
	jt = {Applied bioinformatics},
	language = {eng},
	lr = {20191210},
	mh = {Algorithms; *Artificial Intelligence; Computational Biology/methods; *Computing Methodologies; Gene Expression Profiling/*methods; *Neural Networks, Computer; Neuropeptides/chemistry/classification; *Pattern Recognition, Automated; Protein Interaction Mapping/*methods; Sequence Alignment/*methods; Sequence Analysis/*methods},
	mhda = {2004/06/15 05:00},
	number = {2},
	own = {NLM},
	pages = {67--77},
	phst = {2004/05/08 05:00 {$[$}pubmed{$]$}; 2004/06/15 05:00 {$[$}medline{$]$}; 2004/05/08 05:00 {$[$}entrez{$]$}},
	pl = {New Zealand},
	pmid = {15130823},
	pst = {ppublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't; Review},
	rf = {59},
	rn = {0 (Neuropeptides)},
	sb = {IM},
	status = {MEDLINE},
	title = {Support vector machine applications in bioinformatics.},
	volume = {2},
	year = {2003}}

@article{CERVANTES2020189,
	abstract = {In recent years, an enormous amount of research has been carried out on support vector machines (SVMs) and their application in several fields of science. SVMs are one of the most powerful and robust classification and regression algorithms in multiple fields of application. The SVM has been playing a significant role in pattern recognition which is an extensively popular and active research area among the researchers. Research in some fields where SVMs do not perform well has spurred development of other applications such as SVM for large data sets, SVM for multi classification and SVM for unbalanced data sets. Further, SVM has been integrated with other advanced methods such as evolve algorithms, to enhance the ability of classification and optimize parameters. SVM algorithms have gained recognition in research and applications in several scientific and engineering areas. This paper provides a brief introduction of SVMs, describes many applications and summarizes challenges and trends. Furthermore, limitations of SVMs will be identified. The future of SVMs will be discussed in conjunction with further applications. The applications of SVMs will be reviewed as well, especially in the some fields.},
	author = {Jair Cervantes and Farid Garcia-Lamont and Lisbeth Rodr{\'\i}guez-Mazahua and Asdrubal Lopez},
	date-added = {2025-02-17 13:30:45 -0500},
	date-modified = {2025-02-17 13:30:45 -0500},
	doi = {https://doi.org/10.1016/j.neucom.2019.10.118},
	issn = {0925-2312},
	journal = {Neurocomputing},
	keywords = {SVM, Classification, Machine learning},
	pages = {189-215},
	title = {A comprehensive survey on support vector machine classification: Applications, challenges and trends},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231220307153},
	volume = {408},
	year = {2020},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0925231220307153},
	bdsk-url-2 = {https://doi.org/10.1016/j.neucom.2019.10.118}}

@article{polym17040491,
	abstract = {Polymer science, a discipline focusing on the synthesis, characterization, and application of macromolecules, has increasingly benefited from the adoption of machine learning (ML) techniques. Among these, Support Vector Machines (SVMs) stand out for their ability to handle nonlinear relationships and high-dimensional datasets, which are common in polymer research. This review explores the diverse applications of SVM in polymer science. Key examples include the prediction of mechanical and thermal properties, optimization of polymerization processes, and modeling of degradation mechanisms. The advantages of SVM are contrasted with its challenges, including computational cost, data dependency, and the need for hyperparameter tuning. Future opportunities, such as the development of polymer-specific kernels and integration with real-time manufacturing systems, are also discussed.},
	article-number = {491},
	author = {Malashin, Ivan and Tynchenko, Vadim and Gantimurov, Andrei and Nelyub, Vladimir and Borodulin, Aleksei},
	date-added = {2025-02-17 13:27:45 -0500},
	date-modified = {2025-02-17 13:27:45 -0500},
	doi = {10.3390/polym17040491},
	issn = {2073-4360},
	journal = {Polymers},
	number = {4},
	title = {Support Vector Machines in Polymer Science: A Review},
	url = {https://www.mdpi.com/2073-4360/17/4/491},
	volume = {17},
	year = {2025},
	bdsk-url-1 = {https://www.mdpi.com/2073-4360/17/4/491},
	bdsk-url-2 = {https://doi.org/10.3390/polym17040491}}

@article{info15040235,
	abstract = {Support vector machines (SVMs) are well-known machine learning algorithms for classification and regression applications. In the healthcare domain, they have been used for a variety of tasks including diagnosis, prognosis, and prediction of disease outcomes. This review is an extensive survey on the current state-of-the-art of SVMs developed and applied in the medical field over the years. Many variants of SVM-based approaches have been developed to enhance their generalisation capabilities. We illustrate the most interesting SVM-based models that have been developed and applied in healthcare to improve performance metrics on benchmark datasets, including hybrid classification methods that combine, for instance, optimization algorithms with SVMs. We even report interesting results found in medical applications related to real-world data. Several issues around SVMs, such as selection of hyperparameters and learning from data of questionable quality, are discussed as well. The several variants developed and introduced over the years could be useful in designing new methods to improve performance in critical fields such as healthcare, where accuracy, specificity, and other metrics are crucial. Finally, current research trends and future directions are underlined.},
	article-number = {235},
	author = {Guido, Rosita and Ferrisi, Stefania and Lofaro, Danilo and Conforti, Domenico},
	date-added = {2025-02-17 13:26:11 -0500},
	date-modified = {2025-02-17 13:26:11 -0500},
	doi = {10.3390/info15040235},
	issn = {2078-2489},
	journal = {Information},
	number = {4},
	title = {An Overview on the Advancements of Support Vector Machine Models in Healthcare Applications: A Review},
	url = {https://www.mdpi.com/2078-2489/15/4/235},
	volume = {15},
	year = {2024},
	bdsk-url-1 = {https://www.mdpi.com/2078-2489/15/4/235},
	bdsk-url-2 = {https://doi.org/10.3390/info15040235}}

@article{Cortes:1995aa,
	abstract = {Thesupport-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	date = {1995/09/01},
	date-added = {2025-02-17 10:39:44 -0500},
	date-modified = {2025-02-17 10:39:44 -0500},
	doi = {10.1007/BF00994018},
	id = {Cortes1995},
	isbn = {1573-0565},
	journal = {Machine Learning},
	number = {3},
	pages = {273--297},
	title = {Support-vector networks},
	url = {https://doi.org/10.1007/BF00994018},
	volume = {20},
	year = {1995},
	bdsk-url-1 = {https://doi.org/10.1007/BF00994018}}

@inproceedings{SVM-Kernel-1992,
	abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
	address = {New York, NY, USA},
	author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
	booktitle = {Proceedings of the Fifth Annual Workshop on Computational Learning Theory},
	date-added = {2025-02-17 10:35:38 -0500},
	date-modified = {2025-02-17 10:38:53 -0500},
	doi = {10.1145/130385.130401},
	isbn = {089791497X},
	location = {Pittsburgh, Pennsylvania, USA},
	numpages = {9},
	pages = {144--152},
	publisher = {Association for Computing Machinery},
	series = {COLT '92},
	title = {A training algorithm for optimal margin classifiers},
	url = {https://doi.org/10.1145/130385.130401},
	year = {1992},
	bdsk-url-1 = {https://doi.org/10.1145/130385.130401}}

@article{Perceptron1960,
	author = {Rosenblatt, Frank},
	date-added = {2025-01-10 17:29:07 -0500},
	date-modified = {2025-01-10 17:30:54 -0500},
	doi = {10.1109/JRPROC.1960.287598},
	journal = {Proceedings of the IRE},
	keywords = {Computational modeling;Brain modeling;Laboratories;Computer simulation;Predictive models;Neurons;Pattern recognition;Digital simulation;Mathematical analysis;Retina},
	number = {3},
	pages = {301-309},
	title = {Perceptron Simulation Experiments},
	volume = {48},
	year = {1960},
	bdsk-url-1 = {https://doi.org/10.1109/JRPROC.1960.287598}}

@article{NelderMead-1965,
	abstract = {A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n + 1) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems.},
	author = {Nelder, J. A. and Mead, R.},
	date-added = {2025-01-10 17:10:44 -0500},
	date-modified = {2025-01-10 17:11:03 -0500},
	doi = {10.1093/comjnl/7.4.308},
	eprint = {https://academic.oup.com/comjnl/article-pdf/7/4/308/1013182/7-4-308.pdf},
	issn = {0010-4620},
	journal = {The Computer Journal},
	month = {01},
	number = {4},
	pages = {308-313},
	title = {{A Simplex Method for Function Minimization}},
	url = {https://doi.org/10.1093/comjnl/7.4.308},
	volume = {7},
	year = {1965},
	bdsk-url-1 = {https://doi.org/10.1093/comjnl/7.4.308}}

@misc{ADAM-2014,
	archiveprefix = {arXiv},
	author = {Diederik P. Kingma and Jimmy Ba},
	date-added = {2025-01-10 16:42:32 -0500},
	date-modified = {2025-01-10 16:43:03 -0500},
	eprint = {1412.6980},
	primaryclass = {cs.LG},
	title = {Adam: A Method for Stochastic Optimization},
	url = {https://arxiv.org/abs/1412.6980},
	year = {2017},
	bdsk-url-1 = {https://arxiv.org/abs/1412.6980}}

@article{ADAGrad2011,
	abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	date-added = {2025-01-10 16:38:50 -0500},
	date-modified = {2025-01-10 16:39:21 -0500},
	issn = {1532-4435},
	issue_date = {2/1/2011},
	journal = {J. Mach. Learn. Res.},
	month = jul,
	number = {null},
	numpages = {39},
	pages = {2121--2159},
	publisher = {JMLR.org},
	title = {{Adaptive Subgradient Methods for Online Learning and Stochastic Optimization}},
	volume = {12},
	year = {2011}}

@inproceedings{PSO1995,
	author = {Kennedy, J. and Eberhart, R.},
	booktitle = {Proceedings of ICNN'95 - International Conference on Neural Networks},
	date-added = {2025-01-10 15:11:30 -0500},
	date-modified = {2025-01-10 15:11:46 -0500},
	doi = {10.1109/ICNN.1995.488968},
	keywords = {Particle swarm optimization;Birds;Educational institutions;Marine animals;Testing;Humans;Genetic algorithms;Optimization methods;Artificial neural networks;Performance evaluation},
	pages = {1942-1948 vol.4},
	title = {Particle swarm optimization},
	volume = {4},
	year = {1995},
	bdsk-url-1 = {https://doi.org/10.1109/ICNN.1995.488968}}

@book{Holland:1975aa,
	address = {Ann Arbor},
	annote = {LDR    00944cam  2200253 i 4500
001    318240
005    20150820130553.0
008    750717s1975    miua     b    001 0 eng  
035    $9(DLC)   74078988
906    $a7$bcbc$corignew$d2$eopcn$f19$gy-gencatlg
010    $a   74078988 
020    $a0472084607
040    $aDLC$cDLC$dDLC
050 00 $aQH546$b.H64 1975
082 00 $a574.5
100 1  $aHolland, John H.$q(John Henry),$d1929-2015.
245 10 $aAdaptation in natural and artificial systems :$ban introductory analysis with applications to biology, control, and artificial intelligence /$cby John H. Holland.
260    $aAnn Arbor :$bUniversity of Michigan Press,$c[1975]
300    $aviii, 183 p. :$bill. ;$c25 cm.
504    $aBibliography: p. 175-177.
500    $aIncludes index.
650  0 $aAdaptation (Biology)$xMathematical models.
985    $fea27 2-3-86
991    $bc-GenColl$hQH546$i.H64 1975$p00004559903$tCopy 1$wBOOKS
},
	author = {Holland, John H},
	call-number = {QH546},
	date-added = {2025-01-10 15:07:05 -0500},
	date-modified = {2025-01-10 15:07:05 -0500},
	dewey-call-number = {574.5},
	genre = {Adaptation (Biology)},
	isbn = {0472084607},
	library-id = {74078988},
	publisher = {University of Michigan Press},
	title = {Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence},
	year = {1975}}

@article{Kirkpatrick:1983aa,
	abstract = {There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.},
	author = {Kirkpatrick, S and Gelatt, Jr, C D and Vecchi, M P},
	date-added = {2025-01-10 15:01:27 -0500},
	date-modified = {2025-01-10 15:01:27 -0500},
	doi = {10.1126/science.220.4598.671},
	journal = {Science},
	journal-full = {Science (New York, N.Y.)},
	month = {May},
	number = {4598},
	pages = {671-80},
	pmid = {17813860},
	pst = {ppublish},
	title = {Optimization by simulated annealing},
	volume = {220},
	year = {1983},
	bdsk-url-1 = {https://doi.org/10.1126/science.220.4598.671}}

@article{SG2019,
	abstract = {BACKGROUND: Following visible successes on a wide range of predictive tasks, machine learning techniques are attracting substantial interest from medical researchers and clinicians. We address the need for capacity development in this area by providing a conceptual introduction to machine learning alongside a practical guide to developing and evaluating predictive algorithms using freely-available open source software and public domain data. METHODS: We demonstrate the use of machine learning techniques by developing three predictive models for cancer diagnosis using descriptions of nuclei sampled from breast masses. These algorithms include regularized General Linear Model regression (GLMs), Support Vector Machines (SVMs) with a radial basis function kernel, and single-layer Artificial Neural Networks. The publicly-available dataset describing the breast mass samples (N=683) was randomly split into evaluation (n=456) and validation (n=227) samples. We trained algorithms on data from the evaluation sample before they were used to predict the diagnostic outcome in the validation dataset. We compared the predictions made on the validation datasets with the real-world diagnostic decisions to calculate the accuracy, sensitivity, and specificity of the three models. We explored the use of averaging and voting ensembles to improve predictive performance. We provide a step-by-step guide to developing algorithms using the open-source R statistical programming environment. RESULTS: The trained algorithms were able to classify cell nuclei with high accuracy (.94 -.96), sensitivity (.97 -.99), and specificity (.85 -.94). Maximum accuracy (.96) and area under the curve (.97) was achieved using the SVM algorithm. Prediction performance increased marginally (accuracy =.97, sensitivity =.99, specificity =.95) when algorithms were arranged into a voting ensemble. CONCLUSIONS: We use a straightforward example to demonstrate the theory and practice of machine learning for clinicians and medical researchers. The principals which we demonstrate here can be readily applied to other complex tasks including natural language processing and image recognition.},
	address = {Department of Engineering, University of Cambridge, Trumpington Street, Cambridge, CB2 1PZ, UK.; Department of Surgery, Harvard Medical School, 25 Shattuck Street, Boston, 01225, Massachusetts, USA. cgibbons2@bwh.harvard.edu.; Department of Surgery, Brigham and Women's Hospital, 75 Francis Street, Boston, 01225, Massachusetts, USA. cgibbons2@bwh.harvard.edu.; University of Cambridge Psychometrics Centre, Trumpington Street, Cambridge, CB2 1AG, UK. cgibbons2@bwh.harvard.edu.},
	auid = {ORCID: 0000-0002-4732-7305},
	author = {Sidey-Gibbons, Jenni A M and Sidey-Gibbons, Chris J},
	cois = {ETHICS APPROVAL AND CONSENT TO PARTICIPATE: In this manuscript we use de-identified data from a public repository [17]. The data are included on the BMC Med Res Method website. As such, ethical approval was not required. CONSENT FOR PUBLICATION: All contributing parties consent for the publication of this work. COMPETING INTERESTS: The authors report no competing interests relating to this work. PUBLISHER'S NOTE: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.},
	crdt = {2019/03/21 06:00},
	date = {2019 Mar 19},
	date-added = {2025-01-10 14:50:34 -0500},
	date-modified = {2025-01-10 14:50:34 -0500},
	dcom = {20200210},
	dep = {20190319},
	doi = {10.1186/s12874-019-0681-4},
	edat = {2019/03/21 06:00},
	gr = {CDA 10-019/ImVA/Intramural VA/United States; CDF-2017-10-019/DH{\_}/Department of Health/United Kingdom},
	issn = {1471-2288 (Electronic); 1471-2288 (Linking)},
	jid = {100968545},
	journal = {BMC Med Res Methodol},
	jt = {BMC medical research methodology},
	keywords = {Classification; Computer-assisted; Decision making; Diagnosis; Medical informatics; Programming languages; Supervised machine learning},
	language = {eng},
	lid = {10.1186/s12874-019-0681-4 {$[$}doi{$]$}; 64},
	lr = {20240411},
	mh = {*Algorithms; Breast Neoplasms/*diagnosis; Diagnosis, Computer-Assisted/*methods; Female; Humans; *Machine Learning; *Neural Networks, Computer; Sensitivity and Specificity; Software; *Support Vector Machine},
	mhda = {2020/02/11 06:00},
	month = {Mar},
	number = {1},
	oto = {NOTNLM},
	own = {NLM},
	pages = {64},
	phst = {2018/06/11 00:00 {$[$}received{$]$}; 2019/02/14 00:00 {$[$}accepted{$]$}; 2019/03/21 06:00 {$[$}entrez{$]$}; 2019/03/21 06:00 {$[$}pubmed{$]$}; 2020/02/11 06:00 {$[$}medline{$]$}; 2019/03/19 00:00 {$[$}pmc-release{$]$}},
	pii = {10.1186/s12874-019-0681-4; 681},
	pl = {England},
	pmc = {PMC6425557},
	pmcr = {2019/03/19},
	pmid = {30890124},
	pst = {epublish},
	pt = {Journal Article; Research Support, Non-U.S. Gov't},
	sb = {IM},
	status = {MEDLINE},
	title = {Machine learning in medicine: a practical introduction.},
	volume = {19},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1186/s12874-019-0681-4}}

@article{Francis-QR-1962,
	abstract = {The QR transformation is an analogue to the LR transformation (Rutishauser, 1958) based on unitary transformations. Both these transformations are global iterative methods for finding the eigenvalues of a matrix, the matrix converging in general to triangular form. In Par t1 of this paper the QR transformation was briefly described and we were then principally concerned with proving convergence, the main result being expressed in theorem 3. We also showed that if the matrix is first reduced to almost triangular form important advantages are gained (further advantages will become apparent) and we gave in outline a way in which convergence could be improved. In this part of the paper we consider the practical application of the QR transformation. Two versions of the algorithm have been programmed for the Pegasus computer; these are described and an attempt is made to evaluate the method. Some results and detailed algorithms are given in appendices. Part 1 was published on pp. 265--71 of this volume (Oct. 61).},
	author = {Francis, J. G. F.},
	date-added = {2024-12-17 05:56:32 -0500},
	date-modified = {2024-12-17 05:58:31 -0500},
	doi = {10.1093/comjnl/4.4.332},
	eprint = {https://academic.oup.com/comjnl/article-pdf/4/4/332/8201663/040332.pdf},
	issn = {0010-4620},
	journal = {The Computer Journal},
	month = {01},
	number = {4},
	pages = {332-345},
	title = {{The QR Transformation---Part 2}},
	url = {https://doi.org/10.1093/comjnl/4.4.332},
	volume = {4},
	year = {1962},
	bdsk-url-1 = {https://doi.org/10.1093/comjnl/4.4.332}}

@article{Francis-QR-1961,
	abstract = {The LR transformation, due to Rutishauser, has proved to be a powerful method for finding the eigenvalues of symmetric band matrices. Little attention, however, has been paid to its application to the more difficult problem of finding eigenvalues of general unsymmetric matrices. If the matrices are large two important difficulties are likely to occur. Firstly, triangular decomposition, which is the basis of the method, is by no means always numerically stable, and secondly, the amount of computation required by the method is likely to be very great. This paper describes an algorithm similar to the LR transformation except that the transformations involved in it are all unitary and can thus be expected to by numerically stable. It is then shown that there are various advantages in first converting the matrix to almost-triangular form; in particular, the amount of work involved in the algorithm can then be greatly reduced.Part 1 of the paper is largely concerned with proof of convergence, and the theoretical aspect. Part 2, to be published in January, discussed practical computation and gives results of experiments.},
	author = {Francis, J. G. F.},
	date-added = {2024-12-17 05:54:58 -0500},
	date-modified = {2024-12-17 05:58:21 -0500},
	doi = {10.1093/comjnl/4.3.265},
	eprint = {https://academic.oup.com/comjnl/article-pdf/4/3/265/1080833/040265.pdf},
	issn = {0010-4620},
	journal = {The Computer Journal},
	month = {01},
	number = {3},
	pages = {265-271},
	title = {{The QR Transformation A Unitary Analogue to the LR Transformation---Part 1}},
	url = {https://doi.org/10.1093/comjnl/4.3.265},
	volume = {4},
	year = {1961},
	bdsk-url-1 = {https://doi.org/10.1093/comjnl/4.3.265}}

@book{golub13,
	added-at = {2014-06-23T11:34:50.000+0200},
	author = {Golub, Gene H. and van Loan, Charles F.},
	biburl = {https://www.bibsonomy.org/bibtex/2b9e78e06f69f858cbc968e62c71bb0ef/ytyoun},
	date-added = {2024-12-17 05:20:50 -0500},
	date-modified = {2024-12-17 05:20:50 -0500},
	edition = {Fourth},
	interhash = {a6e3f89a44ff7ccc942c17c894a0dab5},
	intrahash = {b9e78e06f69f858cbc968e62c71bb0ef},
	isbn = {1421407949 9781421407944},
	keywords = {GvL cauchy circulant courant-fischer determinant dft eigenvalues interlacing linear.algebra matrix pseudoinverse textbook},
	publisher = {JHU Press},
	refid = {824733531},
	timestamp = {2017-08-18T08:02:54.000+0200},
	title = {Matrix Computations},
	url = {http://www.cs.cornell.edu/cv/GVL4/golubandvanloan.htm},
	year = 2013,
	bdsk-url-1 = {http://www.cs.cornell.edu/cv/GVL4/golubandvanloan.htm}}

@article{Lloyd-1982,
	author = {Lloyd, S.},
	date-added = {2024-12-16 15:27:58 -0500},
	date-modified = {2024-12-16 15:28:20 -0500},
	doi = {10.1109/TIT.1982.1056489},
	journal = {IEEE Transactions on Information Theory},
	number = {2},
	pages = {129-137},
	title = {Least squares quantization in PCM},
	volume = {28},
	year = {1982},
	bdsk-url-1 = {https://doi.org/10.1109/TIT.1982.1056489}}
