{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b798cf0-f1b9-4ba0-b4c0-e6d677317636",
   "metadata": {},
   "source": [
    "# L5c: Support Vector Machine (SVM) Classification\n",
    "In this lecture, we introduce our last (for now) classification approach, namely [support vector machines (SVMs)](https://en.wikipedia.org/wiki/Support_vector_machine). Support vector machines are a _supervised_ learning approach to learn the best possible separating hyperplane. The key ideas of this lecture are:\n",
    "\n",
    "* A __support vector machine__ is a _supervised_ machine learning algorithm that finds an optimal (linear) hyperplane in an $N$-dimensional space to classify (binary) data points distinctly, maximizing the _margin_ between different classes. The _margin_ in a support vector machine is defined as the distance from the separating hyperplane to the closest data points of either class.\n",
    "* A __hard margin support vector machine__ is a binary linear classifier that finds the optimal hyperplane to separate two classes of data points with the maximum possible _margin_, allowing no misclassifications and requiring the data to be linearly separable.\n",
    "* A __soft margin support vector machine__ is a variant of the SVM algorithm that allows for some misclassification of training data points, enabling it to handle non-linearly separable datasets and reduce overfitting by finding a balance between maximizing the decision boundary margin and minimizing classification errors.\n",
    "\n",
    "Lecture notes for today can be found: [here!](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/Notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6543fd-981f-4864-ba39-560658e45cb6",
   "metadata": {},
   "source": [
    "## Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1becf6-20b1-4396-a990-53d05d229fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generatedatacloud"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"Include.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f2541-7cd5-4344-893a-d4d3bf59a8ae",
   "metadata": {},
   "source": [
    "### Data\n",
    "This lecture will look at a [banknote authentication dataset](https://archive.ics.uci.edu/dataset/267/banknote+authentication) for classification tasks. We'll load the banknote dataset and split it into `training` and `test` data subsets (randomly).\n",
    "* __Training data__: Training datasets are collections of labeled data used to teach machine learning models, allowing these tools to learn patterns and relationships within the data.\n",
    "* __Test data__: Test datasets, on the other hand, are separate sets of labeled data used to evaluate the performance of trained models on unseen examples, providing an unbiased assessment of the _model's generalization capabilities_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4559c-2d27-440f-81ac-346395163975",
   "metadata": {},
   "source": [
    "#### Banknote Authentication Dataset\n",
    "The second dataset we will explore is the [banknote authentication dataset from the UCI archive](https://archive.ics.uci.edu/dataset/267/banknote+authentication). This dataset has `1372` instances of 4 continuous features and an integer $\\{-1,1\\}$ class variable. \n",
    "* __Description__: Data were extracted from images taken from genuine and forged banknote-like specimens.  An industrial camera, usually used for print inspection, was used for digitization. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object, gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tools were used to extract features from images.\n",
    "* __Features__: The data has four continuous features from each image: `variance` of the wavelet transformed image, `skewness` of the wavelet transformed image, `kurtosis` of the wavelet transformed image, and the `entropy` of the wavelet transformed image. The class is $\\{-1,1\\}$ where a class value of `-1` indicates genuine, `1` forged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a1eaff-035b-4da2-83db-7484b7912438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>1372×5 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">1347 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">variance</th><th style = \"text-align: left;\">skewness</th><th style = \"text-align: left;\">curtosis</th><th style = \"text-align: left;\">entropy</th><th style = \"text-align: left;\">class</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">3.6216</td><td style = \"text-align: right;\">8.6661</td><td style = \"text-align: right;\">-2.8073</td><td style = \"text-align: right;\">-0.44699</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">4.5459</td><td style = \"text-align: right;\">8.1674</td><td style = \"text-align: right;\">-2.4586</td><td style = \"text-align: right;\">-1.4621</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">3.866</td><td style = \"text-align: right;\">-2.6383</td><td style = \"text-align: right;\">1.9242</td><td style = \"text-align: right;\">0.10645</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">3.4566</td><td style = \"text-align: right;\">9.5228</td><td style = \"text-align: right;\">-4.0112</td><td style = \"text-align: right;\">-3.5944</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">0.32924</td><td style = \"text-align: right;\">-4.4552</td><td style = \"text-align: right;\">4.5718</td><td style = \"text-align: right;\">-0.9888</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">4.3684</td><td style = \"text-align: right;\">9.6718</td><td style = \"text-align: right;\">-3.9606</td><td style = \"text-align: right;\">-3.1625</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">3.5912</td><td style = \"text-align: right;\">3.0129</td><td style = \"text-align: right;\">0.72888</td><td style = \"text-align: right;\">0.56421</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">2.0922</td><td style = \"text-align: right;\">-6.81</td><td style = \"text-align: right;\">8.4636</td><td style = \"text-align: right;\">-0.60216</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">3.2032</td><td style = \"text-align: right;\">5.7588</td><td style = \"text-align: right;\">-0.75345</td><td style = \"text-align: right;\">-0.61251</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">1.5356</td><td style = \"text-align: right;\">9.1772</td><td style = \"text-align: right;\">-2.2718</td><td style = \"text-align: right;\">-0.73535</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">1.2247</td><td style = \"text-align: right;\">8.7779</td><td style = \"text-align: right;\">-2.2135</td><td style = \"text-align: right;\">-0.80647</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">3.9899</td><td style = \"text-align: right;\">-2.7066</td><td style = \"text-align: right;\">2.3946</td><td style = \"text-align: right;\">0.86291</td><td style = \"text-align: right;\">-1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">1.8993</td><td style = \"text-align: right;\">7.6625</td><td style = \"text-align: right;\">0.15394</td><td style = \"text-align: right;\">-3.1108</td><td style = \"text-align: right;\">-1</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1361</td><td style = \"text-align: right;\">-0.24745</td><td style = \"text-align: right;\">1.9368</td><td style = \"text-align: right;\">-2.4697</td><td style = \"text-align: right;\">-0.80518</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1362</td><td style = \"text-align: right;\">-1.5732</td><td style = \"text-align: right;\">1.0636</td><td style = \"text-align: right;\">-0.71232</td><td style = \"text-align: right;\">-0.8388</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1363</td><td style = \"text-align: right;\">-2.1668</td><td style = \"text-align: right;\">1.5933</td><td style = \"text-align: right;\">0.045122</td><td style = \"text-align: right;\">-1.678</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1364</td><td style = \"text-align: right;\">-1.1667</td><td style = \"text-align: right;\">-1.4237</td><td style = \"text-align: right;\">2.9241</td><td style = \"text-align: right;\">0.66119</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1365</td><td style = \"text-align: right;\">-2.8391</td><td style = \"text-align: right;\">-6.63</td><td style = \"text-align: right;\">10.4849</td><td style = \"text-align: right;\">-0.42113</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1366</td><td style = \"text-align: right;\">-4.5046</td><td style = \"text-align: right;\">-5.8126</td><td style = \"text-align: right;\">10.8867</td><td style = \"text-align: right;\">-0.52846</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1367</td><td style = \"text-align: right;\">-2.41</td><td style = \"text-align: right;\">3.7433</td><td style = \"text-align: right;\">-0.40215</td><td style = \"text-align: right;\">-1.2953</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1368</td><td style = \"text-align: right;\">0.40614</td><td style = \"text-align: right;\">1.3492</td><td style = \"text-align: right;\">-1.4501</td><td style = \"text-align: right;\">-0.55949</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1369</td><td style = \"text-align: right;\">-1.3887</td><td style = \"text-align: right;\">-4.8773</td><td style = \"text-align: right;\">6.4774</td><td style = \"text-align: right;\">0.34179</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1370</td><td style = \"text-align: right;\">-3.7503</td><td style = \"text-align: right;\">-13.4586</td><td style = \"text-align: right;\">17.5932</td><td style = \"text-align: right;\">-2.7771</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1371</td><td style = \"text-align: right;\">-3.5637</td><td style = \"text-align: right;\">-8.3827</td><td style = \"text-align: right;\">12.393</td><td style = \"text-align: right;\">-1.2823</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1372</td><td style = \"text-align: right;\">-2.5419</td><td style = \"text-align: right;\">-0.65804</td><td style = \"text-align: right;\">2.6842</td><td style = \"text-align: right;\">1.1952</td><td style = \"text-align: right;\">1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& variance & skewness & curtosis & entropy & class\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 3.6216 & 8.6661 & -2.8073 & -0.44699 & -1 \\\\\n",
       "\t2 & 4.5459 & 8.1674 & -2.4586 & -1.4621 & -1 \\\\\n",
       "\t3 & 3.866 & -2.6383 & 1.9242 & 0.10645 & -1 \\\\\n",
       "\t4 & 3.4566 & 9.5228 & -4.0112 & -3.5944 & -1 \\\\\n",
       "\t5 & 0.32924 & -4.4552 & 4.5718 & -0.9888 & -1 \\\\\n",
       "\t6 & 4.3684 & 9.6718 & -3.9606 & -3.1625 & -1 \\\\\n",
       "\t7 & 3.5912 & 3.0129 & 0.72888 & 0.56421 & -1 \\\\\n",
       "\t8 & 2.0922 & -6.81 & 8.4636 & -0.60216 & -1 \\\\\n",
       "\t9 & 3.2032 & 5.7588 & -0.75345 & -0.61251 & -1 \\\\\n",
       "\t10 & 1.5356 & 9.1772 & -2.2718 & -0.73535 & -1 \\\\\n",
       "\t11 & 1.2247 & 8.7779 & -2.2135 & -0.80647 & -1 \\\\\n",
       "\t12 & 3.9899 & -2.7066 & 2.3946 & 0.86291 & -1 \\\\\n",
       "\t13 & 1.8993 & 7.6625 & 0.15394 & -3.1108 & -1 \\\\\n",
       "\t14 & -1.5768 & 10.843 & 2.5462 & -2.9362 & -1 \\\\\n",
       "\t15 & 3.404 & 8.7261 & -2.9915 & -0.57242 & -1 \\\\\n",
       "\t16 & 4.6765 & -3.3895 & 3.4896 & 1.4771 & -1 \\\\\n",
       "\t17 & 2.6719 & 3.0646 & 0.37158 & 0.58619 & -1 \\\\\n",
       "\t18 & 0.80355 & 2.8473 & 4.3439 & 0.6017 & -1 \\\\\n",
       "\t19 & 1.4479 & -4.8794 & 8.3428 & -2.1086 & -1 \\\\\n",
       "\t20 & 5.2423 & 11.0272 & -4.353 & -4.1013 & -1 \\\\\n",
       "\t21 & 5.7867 & 7.8902 & -2.6196 & -0.48708 & -1 \\\\\n",
       "\t22 & 0.3292 & -4.4552 & 4.5718 & -0.9888 & -1 \\\\\n",
       "\t23 & 3.9362 & 10.1622 & -3.8235 & -4.0172 & -1 \\\\\n",
       "\t24 & 0.93584 & 8.8855 & -1.6831 & -1.6599 & -1 \\\\\n",
       "\t25 & 4.4338 & 9.887 & -4.6795 & -3.7483 & -1 \\\\\n",
       "\t26 & 0.7057 & -5.4981 & 8.3368 & -2.8715 & -1 \\\\\n",
       "\t27 & 1.1432 & -3.7413 & 5.5777 & -0.63578 & -1 \\\\\n",
       "\t28 & -0.38214 & 8.3909 & 2.1624 & -3.7405 & -1 \\\\\n",
       "\t29 & 6.5633 & 9.8187 & -4.4113 & -3.2258 & -1 \\\\\n",
       "\t30 & 4.8906 & -3.3584 & 3.4202 & 1.0905 & -1 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1372×5 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m variance  \u001b[0m\u001b[1m skewness  \u001b[0m\u001b[1m curtosis  \u001b[0m\u001b[1m entropy   \u001b[0m\u001b[1m class \u001b[0m\n",
       "      │\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "──────┼───────────────────────────────────────────────────\n",
       "    1 │  3.6216      8.6661   -2.8073    -0.44699      -1\n",
       "    2 │  4.5459      8.1674   -2.4586    -1.4621       -1\n",
       "    3 │  3.866      -2.6383    1.9242     0.10645      -1\n",
       "    4 │  3.4566      9.5228   -4.0112    -3.5944       -1\n",
       "    5 │  0.32924    -4.4552    4.5718    -0.9888       -1\n",
       "    6 │  4.3684      9.6718   -3.9606    -3.1625       -1\n",
       "    7 │  3.5912      3.0129    0.72888    0.56421      -1\n",
       "    8 │  2.0922     -6.81      8.4636    -0.60216      -1\n",
       "    9 │  3.2032      5.7588   -0.75345   -0.61251      -1\n",
       "   10 │  1.5356      9.1772   -2.2718    -0.73535      -1\n",
       "   11 │  1.2247      8.7779   -2.2135    -0.80647      -1\n",
       "  ⋮   │     ⋮          ⋮          ⋮          ⋮        ⋮\n",
       " 1363 │ -2.1668      1.5933    0.045122  -1.678         1\n",
       " 1364 │ -1.1667     -1.4237    2.9241     0.66119       1\n",
       " 1365 │ -2.8391     -6.63     10.4849    -0.42113       1\n",
       " 1366 │ -4.5046     -5.8126   10.8867    -0.52846       1\n",
       " 1367 │ -2.41        3.7433   -0.40215   -1.2953        1\n",
       " 1368 │  0.40614     1.3492   -1.4501    -0.55949       1\n",
       " 1369 │ -1.3887     -4.8773    6.4774     0.34179       1\n",
       " 1370 │ -3.7503    -13.4586   17.5932    -2.7771        1\n",
       " 1371 │ -3.5637     -8.3827   12.393     -1.2823        1\n",
       " 1372 │ -2.5419     -0.65804   2.6842     1.1952        1\n",
       "\u001b[36m                                         1351 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_banknote = CSV.read(joinpath(_PATH_TO_DATA, \"data-banknote-authentication.csv\"), DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e838da-0d3d-46a4-8302-830e1782cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_banknote = Matrix(df_banknote); # get the data as a Matrix (alias for Array{Float64,2})\n",
    "number_of_training_examples_banknote = 1000; # how many training points for the banknote dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9ab5a0-cfe2-45cf-95b0-7c665f08179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote_training, banknote_test = let\n",
    "\n",
    "    number_of_features = size(D_banknote,2); # number of cols of housing data\n",
    "    number_of_examples = size(D_banknote,1); # number of rows of housing data\n",
    "    full_index_set = range(1,stop=number_of_examples,step=1) |> collect |> Set;\n",
    "    \n",
    "    # build index sets for training and testing\n",
    "    training_index_set = Set{Int64}();\n",
    "    should_stop_loop = false;\n",
    "    while (should_stop_loop == false)\n",
    "        i = rand(1:number_of_examples);\n",
    "        push!(training_index_set,i);\n",
    "\n",
    "        if (length(training_index_set) == number_of_training_examples_banknote)\n",
    "            should_stop_loop = true;\n",
    "        end\n",
    "    end\n",
    "    test_index_set = setdiff(full_index_set,training_index_set);\n",
    "\n",
    "    # build the test and train datasets -\n",
    "    banknote_training = D_banknote[training_index_set |> collect,:];\n",
    "    banknote_test = D_banknote[test_index_set |> collect,:];\n",
    "\n",
    "    # return\n",
    "    banknote_training,banknote_test\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe512880-fa06-4e0b-ae1f-27fcc676dc3c",
   "metadata": {},
   "source": [
    "## Theory: Support Vector Machine (SVM)\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339857d-9c26-49b7-90ba-3124d5d974b0",
   "metadata": {},
   "source": [
    "## Banknote Classification Problem using a SVM\n",
    "Fill me in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4802b219-3ef9-45ba-91cb-e1e8f8b56578",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = let\n",
    "\n",
    "    # Setup the data that we are using\n",
    "    D = banknote_training; # what dataset are we looking at?\n",
    "    X = D[:,1:end-1] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "\n",
    "    # Train the data -\n",
    "    model = svmtrain(X, y); # we are using the LIBSVM\n",
    "\n",
    "    # return\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c480b-1f20-4e2c-b1c3-ca1dea5b6dfe",
   "metadata": {},
   "source": [
    "__Inference__: Now that we have parameters estimated from the `training` data, we can use those parameters on the `test` dataset to see how well the model can differentiate between an actual banknote and a forgery on data it has never seen. We run the classification operation on the (unseen) test data [using the `classify(...)` method](src/Compute.jl). This method takes a feature array `X` and the (trained) model instance. It returns the estimated labels. \n",
    "* We store the actual (correct) label in the `y_banknote_perceptron::Array{Int64,1}` vector, while the model predicted label is stored in the `ŷ_banknote_perceptron::Array{Int64,1}` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1047fae5-e228-47cf-adb4-be29b78f538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ,y,d = let\n",
    "\n",
    "     # Setup the data that we are using\n",
    "    D = banknote_test; # what dataset are we looking at?\n",
    "    X = D[:,1:end-1] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "    \n",
    "    # Test model on the other half of the data.\n",
    "    ŷ, decision_values = svmpredict(model, X);\n",
    "\n",
    "    # return -\n",
    "    ŷ,y,decision_values\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1f49e72-5e2e-443e-b6bb-6ff1853ab466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×372 Matrix{Float64}:\n",
       " 1.04159  1.14707  -1.09286  1.08968  …  -0.932714  -1.05356  1.21496\n",
       " 0.0      0.0       0.0      0.0          0.0        0.0      0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049b86c-6943-429c-9d31-9597263f4373",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "The confusion matrix is a $2\\times{2}$ matrix that contains four entries: true positive (TP), false positive (FP), true negative (TN), and false negative (FN). [Click me for a confusion matrix schematic!](https://github.com/varnerlab/CHEME-5820-Labs-Spring-2025/blob/main/labs/week-3/L3b/figs/Fig-BinaryConfusionMatrix.pdf). Let's compute these four values [using the `confusion(...)` method](src/Compute.jl) and store them in the `CM_perceptron::Array{Int64,2}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33aa975d-384a-468b-8a7d-5799ff326974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Int64}:\n",
       " 172    0\n",
       "   0  200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM = confusion(y, ŷ) # call with the SVM percepton values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbac12a-920e-4913-b9e1-244cd7398722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
