{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4459d3",
   "metadata": {},
   "source": [
    "# L6c: Applications of the Multiplicative Weights Update Algorithm\n",
    "In this lecture, we'll contibue our discussion of online learning and the multiplicative weights update alogithm. Today, we'll explore a basic implemetation of the algoeiuthm, and some of its applications. The key ideas of this lectyre are:\n",
    "* [The Multiplicative Weights Algorithm (MWA)](https://en.wikipedia.org/wiki/Multiplicative_weight_update_method) is a simple and powerful algorithm for online learning. The MWA is a type of sequential prediction algorithm that updates the weights of experts based on their performance on past predictions. The key idea is to assign higher weights to experts who perform well and lower weights to experts who perform poorly. This allows the algorithm to adapt to changing data distributions and learn from its mistakes.\n",
    "\n",
    "The lecture notes today are taken from [the CMS 139 Course at Caltech prepared by Prof. Thomas Vidick](https://www.cms.caltech.edu/academics/courses/2020-2021-cms-139)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6be8805",
   "metadata": {},
   "source": [
    "## The Multiplicative Weights Update Algorithm (MWA)\n",
    "The Multiplicative Weights Update Algorithm (MWA) is a generalization of the Weighted Majority Algorithm and the Hedge strategy. The MWA is a simple and robust online learning algorithm that can solve many optimization problems. \n",
    "\n",
    "* __Game__: Let $t = 1, 2, \\ldots, T$ denote the current round of the game, and $i$ denote an expert advising us. In each round, we compute a _belief distribution_ $\\mathbf{p}^{(t)} = \\left\\{p_{1}^{(t)}, p_{2}^{(t)}, \\ldots, p_{N}^{(t)}\\right\\}$ over the experts, select a _random_ expert by sampling this distribution and use the selected expert to make a decision. At this point, the _adversary_ (nature) reveals the outcome, and we compute the cost of the decision we've made, where $\\mathbf{m}^{(t)} = \\left\\{m_{1}^{(t)}, m_{2}^{(t)}, \\ldots, m_{N}^{(t)}\\right\\}$ is the overall cost vector and $m_{i}^{(t)}$ is the cost of expert decision $i$ at time $t$. Here, we assume that the costs are in the range $m_{i}^{(t)}\\in[-1, 1]$. Then, the total expected loss at time $t$ is: $L^{(t)} = \\sum_{i=1}^{N}p_{i}^{(t)}m_{i}^{(t)}$, while the overall loss experienced by the _aggregator_ (at the end of the game) is: $L_{A} = \\sum_{t=1}^{T}L^{(t)}$.\n",
    "* __Goal__: The goal of the aggregator (us) is to minimize the total expected loss $L_{A}$ throughout the game, such that we do not experience a loss that is significantly worse than the best decision in hindsight, i.e., $\\min_{i}\\left(\\sum_{t=1}^{T}m_{i}^{(t)}\\right)$.\n",
    "\n",
    "#### Algorithm\n",
    "Fix a learning rate $\\eta\\in\\left(0,{1}/{2}\\right]$, for each expert initialize the weight $w_{i}^{(1)} = 1$. The the costs for a correct/incorrect prediction are in the range $m_{i}^{(t)}\\in[-1, 1]$.\n",
    "\n",
    "For round $t=1,2,\\dots,T$:\n",
    "1. Chose expert $i$ with probability $p_{i}^{(t)} = w_{i}^{(t)}/\\sum_{j=1}^{N}w_{j}^{(t)}$. Ask expert $i$ what the outcome of the experiment should be, denote this outcome as: $y_{i}^{(t)}$.\n",
    "2. The adversary (nature) reveals the true outcome $y_{t}$. Compute the cost of the following expert $i$. If the expert predicted the outcome of the experiment _correctly_ the cost is $m_{i}^{(t)}$ = `-1`, otherwise the cost for an _incorrect prediction_ is $m_{i}^{(t)}$ = `1`. \n",
    "\n",
    "3. Update the weights of expert $i$ as:\n",
    "$$\n",
    "\\begin{align*}\n",
    "w_{i}^{(t+1)} = w_{i}^{(t)}\\cdot\\left(1-\\eta\\cdot{m_{i}^{(t)}}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "4. __Note__: The Caltech notes give the update rule as: $w_{i}^{(t+1)} = w_{i}^{(t)}\\cdot\\exp\\left(-\\eta\\cdot{m}_{i}^{(t)}\\right)$ and $\\eta\\in\\left(0,1\\right)$.\n",
    "\n",
    "__Theorem__: The MWA has the following theoretical guarantee. Assume all costs are in the range $m_{i}^{(t)}\\in[-1, 1]$ and $\\eta\\leq{1}/{2}$. Then the Multiplicative Weights Algorithm (MWA) guarantees that after $T$ rounds, for any expert $i$, we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{t=1}^{T}\\mathbf{m}^{(t)}\\cdot\\mathbf{p}^{(t)} & \\leq \\sum_{t = 1}^{T}m_{i}^{(t)}+\\eta\\sum_{t=1}^{T}|m_{i}^{(t)}|+\\frac{\\ln{n}}{\\eta}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cc194",
   "metadata": {},
   "source": [
    "## Applications of the Multiplicative Weights Update Algorithm\n",
    "The Multiplicative Weights Update (MWA) algorithm has a wide range of applications across various fields, including machine learning, optimization, and game theory. Here are some of its key applications:\n",
    "\n",
    "* __Machine Learning and Prediction__: The MWA method is used in machine learning for online prediction problems, such as learning from expert advice. It helps in combining predictions from multiple experts by iteratively updating weights based on their performance, ensuring that the overall prediction is close to the best expert's performance.\n",
    "\n",
    "* __Game Theory and Portfolio Management__: In game theory, MWA is used to [solve zero-sum games](https://en.wikipedia.org/wiki/Zero-sum_game) by iteratively adjusting strategies based on outcomes. It is also applied in [portfolio management problems](https://www.cis.upenn.edu/~mkearns/finread/helmbold98line.pdf) to optimize investment strategies by dynamically updating the weights of different assets based on their performance. \n",
    "\n",
    "* __Optimization and Linear Programming__: The MWA can be applied to solve linear programs and other optimization problems by iteratively adjusting weights to satisfy constraints. It can efficiently handle systems of linear inequalities and is used in algorithms like Clarkson's for linear programming.\n",
    "\n",
    "* __Complexity Theory and Other Applications__: Additionally, the MWA is used in complexity theory for hardness amplification and in computational geometry for solving specific geometric problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c332e78",
   "metadata": {},
   "source": [
    "## Zero sum games\n",
    "Let's consider the application the mutiplicative weights update algorithm to zero sum games. In [a zero-sum game](https://en.wikipedia.org/wiki/Zero-sum_game), two players have _opposing interests_, and the sum of their payoffs is always zero. The goal of each player is to maximize their own payoff while minimizing the opponent's payoff. The MWA can be used to solve zero-sum games by iteratively adjusting strategies based on outcomes.\n",
    "* __Game__: A set of $k$ players play a zero-sum game. During each turn of the game, each player can choose an action $a\\in\\mathcal{A}$ from the set of actions $\\mathcal{A}$, where the number of possible actions is $\\dim\\mathcal{A} = N$. If we consider $k = 2$, the payoff for the players is represented in a payoff matrix $\\mathbf{M}\\in\\mathbb{R}^{N\\times{N}}$. Let player `1` be the row player, and player `2` be the column player; then $m_{ij}\\in\\mathbf{M}$ is the payoff for player `1` choosing action $i$ and player `2` choosing action $j$. \n",
    "* __Goal__: The goal of each player is to maximize their own payoff while minimizing the opponent's payoff. If the row player chooses action $i$ and the column player chooses action $j$, the payoff for the row player is $-m_{ij}$, and the payoff for the column player is $m_{ij}$. Suppose the row player chooses actions according to a distribution $p$, and the column player chooses actions based on a distribution $q$. The expected payoff for the row player is: $-p^{T}\\mathbf{M}q$ while the expected payoff for the column player is: $p^{T}\\mathbf{M}q$. Thus, the row player wants to mininize $p^{T}\\mathbf{M}q$, while the column player wants to maximize $p^{T}\\mathbf{M}q$.\n",
    "\n",
    "### Von Neumann's Minimax Theorem\n",
    "[Von Neumann's Minimax Theorem](https://en.wikipedia.org/wiki/Minimax_theorem) states that for any two-player zero-sum game, there exists an optimal mixed strategy for each player that minimizes the maximum expected payoff. The optimal mixed strategy for the row player is $p^{*}$ and for the column player is $q^{*}$, such that:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\max_{q}\\min_{p}p^{\\top}\\mathbf{M}q & = \\min_{p}\\max_{q}p^{\\top}\\mathbf{M}q = \\lambda^{\\star}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\lambda^{\\star}$ is the optimal utility (also called the value of the game). The _near optimal_ mixed strategies $p^{*}$ and $q^{*}$ can be computed using the MWA algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154e01b",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "We have a two player zero sum game with a payoff matrix $\\mathbf{M}\\in\\mathbb{R}^{N\\times{N}}$. The row player chooses actions according to a distribution $p$, and the column player chooses actions based on a distribution $q$. The MWA algorithm can be used to compute the near optimal mixed strategies $p^{*}$ and $q^{*}$ for the row and column players, respectively.\n",
    "\n",
    "__Initialize__ the weights $w_{i} = 1$ for all actions $i\\in\\mathcal{A}$, and set the learning rate $\\eta\\in\\left(0,1\\right)$.\n",
    "\n",
    "For round $t=1,2,\\dots,T$:\n",
    "1. The row player chooses an action $i$ with probability $p^{(t)} = \\left\\{w_{i}^{(t)}/\\Phi^{(t)} \\mid i = 1,2,\\dots,N\\right\\}$ where $\\Phi^{(t)} = \\sum_{j=1}^{N}w_{j}^{(t)}$.\n",
    "2. Define $q^{(t)} = \\text{arg}\\max_{q}\\left\\{(p^{(t)})^{\\top}\\mathbf{M}q\\right\\}$ and $m^{(t)} = \\mathbf{M}q^{(t)}$\n",
    "3. Penalize costly decisions by updating the weights as: $w_{i}^{(t+1)} = w_{i}^{(t)}\\cdot\\exp\\left(-\\eta\\cdot{m}_{i}^{(t)}\\right)$ for all actions $i\\in\\mathcal{A}$.\n",
    "\n",
    "where we assume that the payoffs are in the range $m_{ij}\\in[-1, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d050a",
   "metadata": {},
   "source": [
    "## Example: Rock-Paper-Scissors\n",
    "Let's consider an example of a two-player zero-sum game: Rock-Paper-Scissors. In this game, each player simultaneously chooses one of three actions: Rock, Paper, or Scissors. The payoff matrix for this game is as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{M} = \\begin{pmatrix}\n",
    "0 & -1 & 1\\\\\n",
    "1 & 0 & -1\\\\\n",
    "-1 & 1 & 0\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "where the rows correspond to the actions of the row player and the columns correspond to the actions of the column player. The payoff for the row player is $-m_{ij}$, and the payoff for the column player is $m_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d0aeb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Today?\n",
    "That's a wrap! What are some of the interesting things we discussed today?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89af89a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
