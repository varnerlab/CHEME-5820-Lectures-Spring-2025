{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74021a3c-bd9e-4bd3-b5dd-c3f8103d294e",
   "metadata": {},
   "source": [
    "# L9c: Modern Hopfield Networks\n",
    "This lecture covers modern Hopfield networks, which are proto-neural networks used for associative memory tasks. They generalize the original Hopfield network by accommodating continuous data, enabling greater storage capacity and retrieval. Key ideas include:\n",
    "\n",
    "* __Modern Hopfield networks__, also known as Dense Associative Memories, are generalizations of classical Hopfield networks that expand their capabilities to store and retrieve high-dimensional discrete and continuous data. They are designed to overcome the limitations of classical Hopfield networks, which are constrained by linear scaling relationships between the number of input features and the number of stored memories, discrete representations, and sensitivity to correlated patterns.\n",
    "* __Non-linear energy functions__: Modern Hopfield networks utilize strongly non-linear energy functions. These functions allow for the storage (and retrieval) of more patterns than classical Hopfield networks. They enable the storage and retrieval of high-dimensional continuous (potentially correlated, noisy) data.\n",
    "* __Theoretical guarantees__: The theoretical guarantees of modern Hopfield networks (using the Concave-Convex-Procedure (CCCP), and the updated energy functions) are based on the [concept of _attractor dynamics_](https://pubmed.ncbi.nlm.nih.gov/36329249/). Modern networks will converge to a stored pattern when presented with a noisy or incomplete version of that pattern after one update step (each update step corresponds to visiting each neuron once).\n",
    "\n",
    "Background reading for this lecture (and the associated lab) can be found from the following sources:\n",
    "* [Krotov, D., & Hopfield, J.J. (2016). Dense Associative Memory for Pattern Recognition. ArXiv, abs/1606.01164.](https://arxiv.org/abs/1606.01164)\n",
    "* [Demircigil, M., Heusel, J., LÃ¶we, M., Upgang, S., & Vermet, F. (2017). On a Model of Associative Memory with Huge Storage Capacity. Journal of Statistical Physics, 168, 288 - 299.](https://arxiv.org/abs/1702.01929)\n",
    "* [Ramsauer, H., Schafl, B., Lehner, J., Seidl, P., Widrich, M., Gruber, L., Holzleitner, M., Pavlovi'c, M., Sandve, G.K., Greiff, V., Kreil, D.P., Kopp, M., Klambauer, G., Brandstetter, J., & Hochreiter, S. (2020). Hopfield Networks is All You Need. ArXiv, abs/2008.02217.](https://arxiv.org/abs/2008.02217)\n",
    "* [Krotov, D., & Hopfield, J.J. (2020). Large Associative Memory Problem in Neurobiology and Machine Learning. ArXiv, abs/2008.06996.](https://arxiv.org/abs/2008.06996)\n",
    "\n",
    "Today, we are going to walk through the following blog post: [Hopfield Networks is All You Need Blog, GitHub.io](https://ml-jku.github.io/hopfield-layers/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca32950-f6d0-4ca2-b1ce-7ca8142798ca",
   "metadata": {},
   "source": [
    "## Lab\n",
    "In Lab `L9d` we will implement a modern Hopfield network and revisit the image storage and retrival task discussed in `L9a` and `L9b`. However, we'll use [the Simpsons MNIST dataset](https://github.com/alvarobartt/simpsons-mnist) instead of the handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30391152",
   "metadata": {},
   "source": [
    "# Today?\n",
    "That's a wrap! What are some of the interesting things we discussed today?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
